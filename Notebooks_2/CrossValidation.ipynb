{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10052167,"sourceType":"datasetVersion","datasetId":6193679},{"sourceId":10058605,"sourceType":"datasetVersion","datasetId":6198327}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"collapsed_sections":["i4jaUa4P6sPf","U_dRGCIK6-4R","l1FN5Oi57ELl","DgM9M-5q6RbT","eoLstOEE6RbT","PSXZEPd66RbU","1-942JRb6RbU","JjYzjYjN6RbU","xKVpDTol6RbV","7GaGpcvN6RbV","YeB0EXhV6RbV"],"toc_visible":true}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Setup notebook"],"metadata":{"id":"i4jaUa4P6sPf"}},{"cell_type":"code","source":["import os\n","import sys\n","from datetime import datetime\n","\n","import numpy as np\n","import pandas as pd\n","\n","import keras\n","\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import RandomTranslation\n","\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","\n","seed = 47\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","\n","print(f\"TensorFlow version: {tf.__version__}\")\n","print(f\"Keras version: {tfk.__version__}\")\n","print(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")\n","BATCH_SIZE = 64\n","\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","tf.get_logger().setLevel('ERROR')\n","sys.stderr = open(os.devnull, 'w')"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:24.660952Z","iopub.execute_input":"2024-12-04T11:35:24.661529Z","iopub.status.idle":"2024-12-04T11:35:36.921003Z","shell.execute_reply.started":"2024-12-04T11:35:24.661483Z","shell.execute_reply":"2024-12-04T11:35:36.920378Z"},"id":"MM9KGvQM6RbO","outputId":"bb3e114c-55d3-4fc3-9f9e-0842359f26c1"},"outputs":[{"name":"stdout","text":"TensorFlow version: 2.16.1\nKeras version: 3.3.3\nGPU devices: 1\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1733312161.520030      88 service.cc:145] XLA service 0x7ca0a00035b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1733312161.520079      88 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1733312188.508997      88 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":["# Load and prepare data"],"metadata":{"id":"U_dRGCIK6-4R"}},{"cell_type":"code","source":["training_data = np.load(\"/kaggle/input/datasetlomi/training_set_no_outliers.npz\")\n","test_data = np.load(\"/kaggle/input/datasetlomi/test_set.npz\")\n","images = training_data[\"images\"]/255\n","labels = training_data[\"labels\"]\n","print(images.shape)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:36.922652Z","iopub.execute_input":"2024-12-04T11:35:36.923139Z","iopub.status.idle":"2024-12-04T11:35:37.908658Z","shell.execute_reply.started":"2024-12-04T11:35:36.923111Z","shell.execute_reply":"2024-12-04T11:35:37.907979Z"},"id":"gfyw2ZDJ6RbQ","outputId":"4ad7609a-7e8d-4438-d89e-f264ffff2ce4"},"outputs":[{"name":"stdout","text":"(2270, 64, 128)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:37.909753Z","iopub.execute_input":"2024-12-04T11:35:37.910019Z","iopub.status.idle":"2024-12-04T11:35:38.004971Z","shell.execute_reply.started":"2024-12-04T11:35:37.909994Z","shell.execute_reply":"2024-12-04T11:35:38.004191Z"},"id":"0Xvg3Xp46RbR"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def add_channel(image, label):\n","    image = tf.cast(image, tf.float32)\n","    label = tf.cast(label, tf.float32)\n","    image = tf.expand_dims(image, axis=-1)\n","    label = tf.expand_dims(label, axis=-1)\n","    return image, label"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:38.006789Z","iopub.execute_input":"2024-12-04T11:35:38.007076Z","iopub.status.idle":"2024-12-04T11:35:38.011512Z","shell.execute_reply.started":"2024-12-04T11:35:38.007051Z","shell.execute_reply":"2024-12-04T11:35:38.010827Z"},"id":"RYsS1eq86RbR"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["translate_x_0_2_pos = keras.layers.RandomTranslation(height_factor=(0.0,0.0), width_factor=(0.3,0.3), fill_mode=\"constant\", fill_value=0.0)\n","translate_x_0_2_neg = keras.layers.RandomTranslation(height_factor=(0.0,0.0), width_factor=(-0.3,-0.3), fill_mode=\"constant\", fill_value=0.0)\n","translate_y_0_2_pos = keras.layers.RandomTranslation(height_factor=(0.3,0.3), width_factor=(0.0,0.0), fill_mode=\"constant\", fill_value=0.0)\n","translate_y_0_2_neg = keras.layers.RandomTranslation(height_factor=(-0.3,-0.3), width_factor=(0.0,0.0), fill_mode=\"constant\", fill_value=0.0)\n","\n","@tf.function\n","def translate(image, label, seed):\n","    which_translation = tf.random.uniform([], seed=seed)\n","    return tf.case(\n","        [\n","            (which_translation < 0.25, lambda: (translate_x_0_2_pos(image), translate_x_0_2_pos(label))),\n","            (tf.logical_and(which_translation >= 0.25, which_translation < 0.5), lambda: (translate_x_0_2_neg(image), translate_x_0_2_neg(label))),\n","            (tf.logical_and(which_translation >= 0.5, which_translation < 0.75), lambda: (translate_y_0_2_pos(image), translate_y_0_2_pos(label))),\n","            (which_translation >= 0.75, lambda: (translate_y_0_2_neg(image), translate_y_0_2_neg(label))),\n","        ],\n","        default=lambda: (image,label),\n","        exclusive=True\n","    )"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:38.012554Z","iopub.execute_input":"2024-12-04T11:35:38.012909Z","iopub.status.idle":"2024-12-04T11:35:38.531818Z","shell.execute_reply.started":"2024-12-04T11:35:38.012874Z","shell.execute_reply":"2024-12-04T11:35:38.531200Z"},"id":"48Zs6FT76RbR"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["@tf.function\n","def random_flip(image, label, seed=None):\n","    flip_prob = tf.random.uniform([], seed=seed)\n","\n","    image = tf.cond(\n","        flip_prob > 1,\n","        lambda: tf.image.flip_left_right(image),\n","        lambda: image\n","    )\n","    label = tf.cond(\n","        flip_prob > 1,\n","        lambda: tf.image.flip_left_right(label),\n","        lambda: label\n","    )\n","\n","    return image, label\n","\n","@tf.function\n","def random_traslate(image, label, seed=None):\n","    flip_prob = tf.random.uniform([], seed=seed)\n","\n","    image, label = tf.cond(\n","        flip_prob > 0,\n","        lambda: translate(image, label, seed),\n","        lambda: (image, label)\n","    )\n","\n","    return image, label"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:38.532858Z","iopub.execute_input":"2024-12-04T11:35:38.533105Z","iopub.status.idle":"2024-12-04T11:35:38.539946Z","shell.execute_reply.started":"2024-12-04T11:35:38.533081Z","shell.execute_reply":"2024-12-04T11:35:38.539405Z"},"id":"0dPGgKi26RbR"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def to_datasett(X_train, y_train, augmentation = False, seed = seed, shuffle = False, batch_size = BATCH_SIZE):\n","    dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","\n","    if shuffle:\n","        dataset = dataset.shuffle(buffer_size=batch_size * 2, seed=seed)\n","\n","    dataset = dataset.map(\n","                    lambda x, y: add_channel(x, y),\n","                    num_parallel_calls=tf.data.AUTOTUNE\n","                   )\n","\n","    if augmentation:\n","        dataset = dataset.map(\n","                        lambda x, y: random_traslate(x,y,seed),\n","                        num_parallel_calls=tf.data.AUTOTUNE\n","                    )\n","\n","\n","    \"\"\"if augmentation:\n","        dataset = dataset.map(\n","                        lambda x, y: (tf.squeeze(x, axis=-1), tf.squeeze(y, axis=-1)),\n","                        num_parallel_calls=tf.data.AUTOTUNE\n","                    )\"\"\"\n","    # Batch the data\n","    dataset = dataset.batch(batch_size, drop_remainder=False)\n","    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","\n","    return dataset"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:38.540764Z","iopub.execute_input":"2024-12-04T11:35:38.540972Z","iopub.status.idle":"2024-12-04T11:35:38.552056Z","shell.execute_reply.started":"2024-12-04T11:35:38.540951Z","shell.execute_reply":"2024-12-04T11:35:38.551559Z"},"id":"bcSPJK086RbS"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["train_dataset = to_datasett(X_train, y_train, augmentation = True)\n","#train_dataset_no_aug = to_datasett(X_train, y_train, augmentation = False)\n","\n","#train_dataset = train_dataset_aug.concatenate(train_dataset_no_aug)\n","\n","val_dataset = to_datasett(X_val, y_val, augmentation=False)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:38.552990Z","iopub.execute_input":"2024-12-04T11:35:38.553233Z","iopub.status.idle":"2024-12-04T11:35:39.948835Z","shell.execute_reply.started":"2024-12-04T11:35:38.553201Z","shell.execute_reply":"2024-12-04T11:35:39.948093Z"},"id":"1kRWIWAj6RbS"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Model definition"],"metadata":{"id":"l1FN5Oi57ELl"}},{"cell_type":"code","source":["num_classes = 5\n","epochs = 1000\n","patience = 20\n","complexLoss = 4\n","batch_size = 64\n","seed = 45\n","learning_rate = 0.001\n","patience = 20"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:39.949965Z","iopub.execute_input":"2024-12-04T11:35:39.950234Z","iopub.status.idle":"2024-12-04T11:35:39.954359Z","shell.execute_reply.started":"2024-12-04T11:35:39.950204Z","shell.execute_reply":"2024-12-04T11:35:39.953661Z"},"id":"lr_lLFi-6RbS"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def unetpp_block(inputs, filters, name):\n","    \"\"\"\n","    Crea un nodo della U-Net++ che combina input provenienti da diversi livelli.\n","    \"\"\"\n","    if len(inputs) > 1:\n","        x = tfkl.Concatenate(name=f\"{name}_concat\")(inputs)\n","    else:\n","        x = inputs[0]\n","\n","    # Primo blocco convoluzionale con LeakyReLU\n","    x = tfkl.Conv2D(filters, kernel_size=3, padding=\"same\", name=f\"{name}_conv1\")(x)\n","    x = tfkl.BatchNormalization(name=f\"{name}_bn1\")(x)\n","    x = tfkl.LeakyReLU(negative_slope=0.1, name=f\"{name}_leakyrelu1\")(x)  # Sostituito alpha con negative_slope\n","\n","    # Secondo blocco convoluzionale con LeakyReLU\n","    x = tfkl.Conv2D(filters, kernel_size=3, padding=\"same\", name=f\"{name}_conv2\")(x)\n","    x = tfkl.BatchNormalization(name=f\"{name}_bn2\")(x)\n","    x = tfkl.LeakyReLU(negative_slope=0.1, name=f\"{name}_leakyrelu2\")(x)  # Sostituito alpha con negative_slope\n","\n","    return x\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:39.958090Z","iopub.execute_input":"2024-12-04T11:35:39.958435Z","iopub.status.idle":"2024-12-04T11:35:40.015874Z","shell.execute_reply.started":"2024-12-04T11:35:39.958397Z","shell.execute_reply":"2024-12-04T11:35:40.015091Z"},"id":"EbUILCzR6RbT"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def get_unetpp(input_shape=(64, 128,1), num_classes=5, filters=[32, 64, 128, 256, 512], seed=seed):\n","    tf.random.set_seed(seed)\n","    input_layer = tfkl.Input(shape=input_shape, name=\"input_layer\")\n","\n","    # Downsampling path\n","    x00 = unetpp_block([input_layer], filters[0], name=\"x00\")\n","    d0 = tfkl.MaxPooling2D(pool_size=(2, 2))(x00)\n","\n","    x10 = unetpp_block([d0], filters[1], name=\"x10\")\n","    d1 = tfkl.MaxPooling2D(pool_size=(2, 2))(x10)\n","\n","    x20 = unetpp_block([d1], filters[2], name=\"x20\")\n","    d2 = tfkl.MaxPooling2D(pool_size=(2, 2))(x20)\n","\n","    x30 = unetpp_block([d2], filters[3], name=\"x30\")\n","    d3 = tfkl.MaxPooling2D(pool_size=(2, 2))(x30)\n","\n","    x40 = unetpp_block([d3], filters[4], name=\"x40\")\n","\n","    # Upsampling path with dense connections\n","    x01 = unetpp_block([x00, tfkl.UpSampling2D(size=(2, 2))(x10)], filters[0], name=\"x01\")\n","    x11 = unetpp_block([x10, tfkl.UpSampling2D(size=(2, 2))(x20)], filters[1], name=\"x11\")\n","    x02 = unetpp_block([x01, tfkl.UpSampling2D(size=(2, 2))(x11)], filters[0], name=\"x02\")\n","\n","    x21 = unetpp_block([x20, tfkl.UpSampling2D(size=(2, 2))(x30)], filters[2], name=\"x21\")\n","    x12 = unetpp_block([x11, tfkl.UpSampling2D(size=(2, 2))(x21)], filters[1], name=\"x12\")\n","    x03 = unetpp_block([x02, tfkl.UpSampling2D(size=(2, 2))(x12)], filters[0], name=\"x03\")\n","\n","    x31 = unetpp_block([x30, tfkl.UpSampling2D(size=(2, 2))(x40)], filters[3], name=\"x31\")\n","    x22 = unetpp_block([x21, tfkl.UpSampling2D(size=(2, 2))(x31)], filters[2], name=\"x22\")\n","    x13 = unetpp_block([x12, tfkl.UpSampling2D(size=(2, 2))(x22)], filters[1], name=\"x13\")\n","    x04 = unetpp_block([x03, tfkl.UpSampling2D(size=(2, 2))(x13)], filters[0], name=\"x04\")\n","\n","    # Output Layer\n","    output_layer = tfkl.Conv2D(num_classes, kernel_size=1, activation=\"softmax\", name=\"output_layer\")(x04)\n","\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name=\"UNetPlusPlus\")\n","    return model"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:40.017290Z","iopub.execute_input":"2024-12-04T11:35:40.017575Z","iopub.status.idle":"2024-12-04T11:35:40.031677Z","shell.execute_reply.started":"2024-12-04T11:35:40.017550Z","shell.execute_reply":"2024-12-04T11:35:40.031163Z"},"id":"SLbBRXfY6RbT"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["#model = get_unetpp()\n","\n","# Print a detailed summary of the model with expanded nested layers and trainable parameters.\n","#model.summary(expand_nested=True, show_trainable=True)\n","\n","# Generate and display a graphical representation of the model architecture.\n","#tf.keras.utils.plot_model(model, show_trainable=True, expand_nested=True, dpi=70)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:40.032690Z","iopub.execute_input":"2024-12-04T11:35:40.032942Z","iopub.status.idle":"2024-12-04T11:35:40.046398Z","shell.execute_reply.started":"2024-12-04T11:35:40.032919Z","shell.execute_reply":"2024-12-04T11:35:40.045918Z"},"id":"S99k402I6RbT"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# **MeanIntersectionOverUnion**"],"metadata":{"id":"DgM9M-5q6RbT"}},{"cell_type":"code","source":["class MeanIntersectionOverUnion(tf.keras.metrics.MeanIoU):\n","    def __init__(self, num_classes, labels_to_exclude=[0], name=\"mean_iou\", dtype=None, **kwargs):\n","        \"\"\"\n","        Aggiunto **kwargs per gestire parametri inattesi come `ignore_class`.\n","        \"\"\"\n","        super(MeanIntersectionOverUnion, self).__init__(num_classes=num_classes, name=name, dtype=dtype)\n","        if labels_to_exclude is None:\n","            labels_to_exclude = [0]\n","        self.labels_to_exclude = labels_to_exclude\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        y_pred = tf.math.argmax(y_pred, axis=-1)\n","        y_true = tf.reshape(y_true, [-1])\n","        y_pred = tf.reshape(y_pred, [-1])\n","\n","        for label in self.labels_to_exclude:\n","            mask = tf.not_equal(y_true, label)\n","            y_true = tf.boolean_mask(y_true, mask)\n","            y_pred = tf.boolean_mask(y_pred, mask)\n","\n","        return super().update_state(y_true, y_pred, sample_weight)\n","\n","# Registra la classe personalizzata\n","tf.keras.utils.get_custom_objects()[\"MeanIntersectionOverUnion\"] = MeanIntersectionOverUnion"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:40.047267Z","iopub.execute_input":"2024-12-04T11:35:40.047512Z","iopub.status.idle":"2024-12-04T11:35:40.065454Z","shell.execute_reply.started":"2024-12-04T11:35:40.047488Z","shell.execute_reply":"2024-12-04T11:35:40.064948Z"},"id":"8Z2y-mlG6RbT"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# **weighted_loss**"],"metadata":{"id":"eoLstOEE6RbT"}},{"cell_type":"code","source":["labels_flat = y_train.reshape(-1)  # Appiattisci l'array per considerare tutti i pixel\n","\n","# Conta la frequenza di ogni classe\n","num_classes = 5  # Modifica in base al numero di classi nel tuo dataset\n","labels_flat = labels_flat.astype(int)  # Converte i dati in interi\n","\n","# Conta la frequenza di ogni classe\n","class_frequencies = np.bincount(labels_flat, minlength=num_classes)\n","\n","# Stampa le frequenze\n","print(f\"Frequenze delle classi: {class_frequencies}\")\n","\n","total_samples = np.sum(class_frequencies)\n","class_weights = total_samples / (len(class_frequencies) * class_frequencies)\n","print(f\"Pesi di classe: {class_weights}\")\n","\n","# Conversione in dizionario per TensorFlow\n","class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n","\n","# Funzione di perdita con pesi di classe\n","loss = tf.keras.losses.SparseCategoricalCrossentropy()\n","\n","\n","def weighted_loss(y_true, y_pred):\n","    y_true = tf.cast(y_true, tf.int32)  # Assicurati che i valori siano interi\n","    weights = tf.gather(class_weights, y_true)  # Recupera i pesi in base alle etichette\n","    weights = tf.cast(weights, tf.float32)  # Converte i pesi in float32\n","    unweighted_loss = loss(y_true, y_pred)\n","    weighted_loss = unweighted_loss * weights\n","    return tf.reduce_mean(weighted_loss)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:40.066711Z","iopub.execute_input":"2024-12-04T11:35:40.067039Z","iopub.status.idle":"2024-12-04T11:35:40.156257Z","shell.execute_reply.started":"2024-12-04T11:35:40.067015Z","shell.execute_reply":"2024-12-04T11:35:40.155564Z"},"id":"SZFuIre96RbU","outputId":"c5473991-639d-4643-9146-1f4e050d3954"},"outputs":[{"name":"stdout","text":"Frequenze delle classi: [3919495 4121335 3893379 2921642   20821]\nPesi di classe: [  0.75911167   0.72193462   0.76420364   1.01837747 142.90064838]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":["# **Dice score**"],"metadata":{"id":"PSXZEPd66RbU"}},{"cell_type":"code","source":["class DiceScore(tf.keras.metrics.Metric):\n","    def __init__(self, name=\"DiceScore\", smooth=1e-6, **kwargs):\n","        super(DiceScore, self).__init__(name=name, **kwargs)\n","        self.smooth = smooth\n","        self.true_positive = self.add_weight(name=\"true_positive\", initializer=\"zeros\")\n","        self.pred_positive = self.add_weight(name=\"pred_positive\", initializer=\"zeros\")\n","        self.actual_positive = self.add_weight(name=\"actual_positive\", initializer=\"zeros\")\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        # Rimuovi il canale dal tensor y_true (se presente)\n","        y_true = tf.squeeze(y_true, axis=-1)\n","\n","        # Calcola le etichette predette come argmax\n","        y_pred = tf.argmax(y_pred, axis=-1)\n","        y_pred = tf.cast(y_pred, tf.float32)  # Assicurati che sia float32\n","\n","        # Calcola l'intersezione e le somme\n","        intersection = tf.reduce_sum(y_true * y_pred)\n","        pred_sum = tf.reduce_sum(y_pred)\n","        true_sum = tf.reduce_sum(y_true)\n","\n","        # Aggiorna gli stati\n","        self.true_positive.assign_add(intersection)\n","        self.pred_positive.assign_add(pred_sum)\n","        self.actual_positive.assign_add(true_sum)\n","\n","    def result(self):\n","        numerator = 2 * self.true_positive + self.smooth\n","        denominator = self.pred_positive + self.actual_positive + self.smooth\n","        return numerator / denominator\n","\n","    def reset_states(self):\n","        self.true_positive.assign(0)\n","        self.pred_positive.assign(0)\n","        self.actual_positive.assign(0)\n","\n","tf.keras.utils.get_custom_objects()[\"DiceScore\"] = DiceScore"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:40.157836Z","iopub.execute_input":"2024-12-04T11:35:40.158140Z","iopub.status.idle":"2024-12-04T11:35:40.164823Z","shell.execute_reply.started":"2024-12-04T11:35:40.158113Z","shell.execute_reply":"2024-12-04T11:35:40.164211Z"},"id":"XtlyfJ2C6RbU"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["class DiceLoss(tf.keras.losses.Loss):\n","    def __init__(self, smooth=1e-6, name=\"DiceLoss\"):\n","        super(DiceLoss, self).__init__(name=name)\n","        self.smooth = smooth\n","\n","    def call(self, y_true, y_pred):\n","        # Rimuovi la dimensione del canale da y_true (se necessario)\n","        y_true = tf.squeeze(y_true, axis=-1)\n","\n","        # Converti y_pred in probabilità (softmax già applicato nei modelli multi-classe)\n","        y_pred = tf.argmax(y_pred, axis=-1)\n","        y_pred = tf.cast(y_pred, tf.float32)  # Assicurati che sia float32\n","\n","        # Calcolo dell'intersezione e della somma\n","        intersection = tf.reduce_sum(y_true * y_pred)\n","        union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n","\n","        # Calcolo del Dice Score\n","        dice_score = (2. * intersection + self.smooth) / (union + self.smooth)\n","\n","        # La perdita è 1 - Dice Score\n","        dice_loss = 1 - dice_score\n","        return dice_loss\n","\n","    def get_config(self):\n","        return {\"smooth\": self.smooth, \"name\": self.name}"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:40.165908Z","iopub.execute_input":"2024-12-04T11:35:40.166173Z","iopub.status.idle":"2024-12-04T11:35:40.182870Z","shell.execute_reply.started":"2024-12-04T11:35:40.166149Z","shell.execute_reply":"2024-12-04T11:35:40.182283Z"},"id":"kdoGl3X86RbU"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# **FocalLoss**"],"metadata":{"id":"1-942JRb6RbU"}},{"cell_type":"code","source":["class FocalLoss(tf.keras.losses.Loss):\n","    def __init__(self, gamma=2.0, alpha=0.25, name=\"FocalLoss\"):\n","        super(FocalLoss, self).__init__(name=name)\n","        self.gamma = gamma\n","        self.alpha = alpha\n","\n","    def call(self, y_true, y_pred):\n","        # Clip y_pred per evitare log(0)\n","        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0)\n","\n","        # Calcolo della focal loss\n","        cross_entropy = -y_true * tf.math.log(y_pred)\n","        weight = self.alpha * tf.math.pow(1 - y_pred, self.gamma)\n","        focal_loss = tf.reduce_sum(weight * cross_entropy, axis=-1)\n","        return tf.reduce_mean(focal_loss)\n","\n","    def get_config(self):\n","        return {\"gamma\": self.gamma, \"alpha\": self.alpha, \"name\": self.name}"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:40.184043Z","iopub.execute_input":"2024-12-04T11:35:40.184705Z","iopub.status.idle":"2024-12-04T11:35:40.199380Z","shell.execute_reply.started":"2024-12-04T11:35:40.184667Z","shell.execute_reply":"2024-12-04T11:35:40.198793Z"},"id":"mOoyb2UT6RbU"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# **BoundaryLoss**"],"metadata":{"id":"JjYzjYjN6RbU"}},{"cell_type":"code","source":["from tensorflow.python.keras import backend as K\n","\n","def compute_signed_distance_map(mask):\n","    # Creiamo un kernel che emula l'effetto di una convoluzione che calcola la distanza ai bordi\n","    # Questo è un esempio di kernel semplice per la distanza\n","    # Aggiungi un canale per la convoluzione, se necessario\n","    mask_expanded = tf.expand_dims(mask, axis=-1)  # Forma: [batch_size, height, width, 1]\n","\n","    # Definiamo il kernel per la mappa di distanza (3x3)\n","    kernel = tf.convert_to_tensor([[ [1], [1], [1]],\n","                                    [ [1], [-7], [1]],\n","                                    [ [1], [1], [1]]], dtype=tf.float32)\n","\n","    kernel = tf.reshape(kernel, (3, 3, 1, 1))  # Forma del kernel: [3, 3, 1, 1]\n","\n","    # Applichiamo la convoluzione 2D alla maschera\n","    distance_map = tf.nn.conv2d(mask_expanded, kernel, strides=[1, 1, 1, 1], padding='SAME')\n","\n","    # Normalizziamo la distanza (valore assoluto)\n","    distance_map = tf.abs(distance_map)\n","\n","    return distance_map\n","\n","# Definizione della Boundary Loss\n","class BoundaryLoss(tf.keras.losses.Loss):\n","    def __init__(self, name=\"BoundaryLoss\"):\n","        super(BoundaryLoss, self).__init__(name=name)\n","\n","    def call(self, y_true, y_pred):\n","        OUTPUT_SHAPE = (64, 128, 1)\n","        y_pred_bd = tfkl.MaxPooling2D((3, 3), strides=(1, 1), padding='same', input_shape=OUTPUT_SHAPE)(1 - y_pred)\n","        y_true_bd = tfkl.MaxPooling2D((3, 3), strides=(1, 1), padding='same', input_shape=OUTPUT_SHAPE)(1 - y_true)\n","        y_pred_bd = y_pred_bd - (1 - y_pred)\n","        y_true_bd = y_true_bd - (1 - y_true)\n","\n","        y_pred_bd_ext = tfkl.MaxPooling2D((5, 5), strides=(1, 1), padding='same', input_shape=OUTPUT_SHAPE)(1 - y_pred)\n","        y_true_bd_ext = tfkl.MaxPooling2D((5, 5), strides=(1, 1), padding='same', input_shape=OUTPUT_SHAPE)(1 - y_true)\n","        y_pred_bd_ext = y_pred_bd_ext - (1 - y_pred)\n","        y_true_bd_ext = y_true_bd_ext - (1 - y_true)\n","\n","        P = K.sum(y_pred_bd * y_true_bd_ext) / K.sum(y_pred_bd) + 1e-7\n","        R = K.sum(y_true_bd * y_pred_bd_ext) / K.sum(y_true_bd) + 1e-7\n","        F1_Score = 2 * P * R / (P + R + 1e-7)\n","        # print(f'Precission: {P.eval()}, Recall: {R.eval()}, F1: {F1_Score.eval()}')\n","        loss = K.mean(1 - F1_Score)\n","        # print(f\"Loss:{loss.eval()}\")\n","        return loss\n","\n","    def get_config(self):\n","        return {\"name\": self.name}"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:40.200716Z","iopub.execute_input":"2024-12-04T11:35:40.201506Z","iopub.status.idle":"2024-12-04T11:35:40.210839Z","shell.execute_reply.started":"2024-12-04T11:35:40.201476Z","shell.execute_reply":"2024-12-04T11:35:40.210278Z"},"id":"IsprqiUX6RbU"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# **Loss combination**"],"metadata":{"id":"xKVpDTol6RbV"}},{"cell_type":"code","source":["class UnifiedLoss(tf.keras.losses.Loss):\n","    def __init__(self, dice_weight=0.5, focal_weight=0.3, boundary_weight=0.2,\n","                 gamma=2.0, alpha=0.25, smooth=1e-6, name=\"UnifiedLoss\"):\n","        super(UnifiedLoss, self).__init__(name=name)\n","        self.dice_loss = DiceLoss(smooth=smooth)\n","        self.focal_loss = FocalLoss(gamma=gamma, alpha=alpha)\n","        self.boundary_loss = BoundaryLoss()\n","        self.dice_weight = dice_weight\n","        self.focal_weight = focal_weight\n","        self.boundary_weight = boundary_weight\n","\n","    def call(self, y_true, y_pred):\n","        dice = self.dice_loss(y_true, y_pred)\n","        focal = self.focal_loss(y_true, y_pred)\n","        boundary = self.boundary_loss(y_true, y_pred)\n","        return (self.dice_weight * dice +\n","                self.focal_weight * focal +\n","                self.boundary_weight * boundary)\n","\n","    def get_config(self):\n","        return {\n","            \"dice_weight\": self.dice_weight,\n","            \"focal_weight\": self.focal_weight,\n","            \"boundary_weight\": self.boundary_weight,\n","            \"gamma\": self.gamma,\n","            \"alpha\": self.alpha,\n","            \"smooth\": self.smooth,\n","            \"name\": self.name\n","        }\n","\n","tf.keras.utils.get_custom_objects()[\"UnifiedLoss\"] = UnifiedLoss"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:40.211980Z","iopub.execute_input":"2024-12-04T11:35:40.212323Z","iopub.status.idle":"2024-12-04T11:35:40.225126Z","shell.execute_reply.started":"2024-12-04T11:35:40.212287Z","shell.execute_reply":"2024-12-04T11:35:40.224576Z"},"id":"XWQOISZk6RbV"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# **Per la visualizzazione durante il trainig**"],"metadata":{"id":"7GaGpcvN6RbV"}},{"cell_type":"code","source":["def create_segmentation_colormap(num_classes):\n","    \"\"\"\n","    Create a linear colormap using a predefined palette.\n","    Uses 'viridis' as default because it is perceptually uniform\n","    and works well for colorblindness.\n","    \"\"\"\n","    return plt.cm.viridis(np.linspace(0, 1, num_classes))\n","\n","def apply_colormap(label, colormap=None):\n","    \"\"\"\n","    Apply the colormap to a label.\n","    \"\"\"\n","    # Ensure label is 2D\n","    label = np.squeeze(label)\n","\n","    if colormap is None:\n","        num_classes = len(np.unique(label))\n","        colormap = create_segmentation_colormap(num_classes)\n","\n","    # Apply the colormap\n","    colored = colormap[label.astype(int)]\n","\n","    return colored\n","\n","class VizCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, dataset, frequency=5, num_classes=2):\n","        super().__init__()\n","        self.dataset = dataset\n","        self.frequency = frequency\n","        self.num_classes = num_classes\n","        self.dataset_iter = iter(dataset)  # Crea un iteratore per accedere ai dati\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if epoch % self.frequency == 0:  # Visualizza solo ogni \"frequency\" epochs\n","            try:\n","                # Estrai un batch di dati\n","                image, label = next(self.dataset_iter)\n","            except StopIteration:\n","                # Ricrea l'iteratore se i dati sono terminati\n","                self.dataset_iter = iter(self.dataset)\n","                image, label = next(self.dataset_iter)\n","\n","            # Prepara i dati per la predizione\n","            image = tf.expand_dims(image[0], 0)  # Estrai una sola immagine dal batch\n","            label = label[0]  # Etichetta corrispondente\n","            pred = self.model.predict(image, verbose=0)\n","            y_pred = tf.math.argmax(pred, axis=-1)\n","            y_pred = y_pred.numpy()\n","\n","            # Creazione della mappa colori\n","            colormap = create_segmentation_colormap(self.num_classes)\n","\n","            plt.figure(figsize=(16, 4))\n","\n","            # Immagine di input\n","            plt.subplot(1, 3, 1)\n","            plt.imshow(image[0])\n","            plt.title(\"Input Image\")\n","            plt.axis('off')\n","\n","            # Ground truth\n","            plt.subplot(1, 3, 2)\n","            colored_label = apply_colormap(label.numpy(), colormap)\n","            plt.imshow(colored_label)\n","            plt.title(\"Ground Truth Mask\")\n","            plt.axis('off')\n","\n","            # Predizione\n","            plt.subplot(1, 3, 3)\n","            colored_pred = apply_colormap(y_pred[0], colormap)\n","            plt.imshow(colored_pred)\n","            plt.title(\"Predicted Mask\")\n","            plt.axis('off')\n","\n","            plt.tight_layout()\n","            plt.show()\n","            plt.close()"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:40.226345Z","iopub.execute_input":"2024-12-04T11:35:40.226610Z","iopub.status.idle":"2024-12-04T11:35:40.244315Z","shell.execute_reply.started":"2024-12-04T11:35:40.226586Z","shell.execute_reply":"2024-12-04T11:35:40.243797Z"},"id":"neBRNhDe6RbV"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_accuracy',\n","    mode='max',\n","    patience=patience,\n","    restore_best_weights=True\n",")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:40.245228Z","iopub.execute_input":"2024-12-04T11:35:40.245430Z","iopub.status.idle":"2024-12-04T11:35:40.258600Z","shell.execute_reply.started":"2024-12-04T11:35:40.245409Z","shell.execute_reply":"2024-12-04T11:35:40.258096Z"},"id":"a-CQnKcL6RbV"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["#  **Cross validation**"],"metadata":{"id":"YeB0EXhV6RbV"}},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","\n","# Define the function for cross-validation using KFold\n","def cross_validate(n_splits=5, batch_size=batch_size, dice_weight=0.5, focal_weight=0.3, boundary_weight=0.2):\n","    # Initialize KFold with the specified number of splits and shuffling\n","    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","\n","    fold_no = 1  # Track the fold number\n","    val_losses = []  # Store validation losses for each fold\n","    val_accuracies = []  # Store validation accuracies for each fold\n","\n","    # Extract all images and labels from the training dataset\n","    # Assumes `train_dataset` contains image and label pairs\n","    images = []\n","    labels = []\n","    for image, label in train_dataset:\n","        images.append(image.numpy())\n","        labels.append(label.numpy())\n","\n","    # Convert lists of images and labels into numpy arrays\n","    images = np.concatenate(images, axis=0)\n","    labels = np.concatenate(labels, axis=0)\n","\n","    # Perform KFold cross-validation\n","    for train_idx, val_idx in kfold.split(images, labels):\n","        # Split the data into training and validation sets\n","        X_train, X_val = images[train_idx], images[val_idx]\n","        y_train, y_val = labels[train_idx], labels[val_idx]\n","\n","        # Create TensorFlow datasets for training and validation\n","        train_dataset_fold = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n","        val_dataset_fold = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n","\n","        # Initialize a new model for this fold\n","        model = get_unetpp()\n","\n","        # Compile the model with the specified loss and metrics\n","        model.compile(\n","            loss=UnifiedLoss(dice_weight=dice_weight, focal_weight=focal_weight, boundary_weight=boundary_weight),\n","            optimizer=tf.keras.optimizers.AdamW(learning_rate=learning_rate),\n","            metrics=[\n","                \"accuracy\",  # Standard accuracy metric\n","                DiceScore(),  # Custom Dice Score metric\n","                MeanIntersectionOverUnion(num_classes=num_classes, labels_to_exclude=[0])  # Mean IoU ignoring label 0\n","            ]\n","        )\n","\n","        # Train the model on the current fold\n","        history = model.fit(\n","            train_dataset_fold,\n","            epochs=epochs,\n","            validation_data=val_dataset_fold,\n","            callbacks=[early_stopping],\n","            verbose=0  # Suppress verbose output\n","        )\n","\n","        # Extract the final validation loss and accuracy\n","        val_loss = history.history['val_loss'][-1]\n","        val_accuracy = history.history.get('val_accuracy', [None])[-1]\n","\n","        # Append the results to their respective lists\n","        val_losses.append(val_loss)\n","        val_accuracies.append(val_accuracy)\n","\n","        # Delete the model to free memory\n","        del model\n","\n","        # Early exit if accuracy is too low\n","        if val_accuracy < 0.5:\n","            print(\"Drop the training, too slow accuracy. Continue with next set of values.\")\n","            break\n","\n","        print(f\"Fold {fold_no} - Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","        fold_no += 1\n","\n","    # Calculate the average validation loss and accuracy across all folds\n","    avg_val_loss = np.mean(val_losses)\n","    avg_val_accuracy = np.mean(val_accuracies)\n","\n","    print(f\"\\nAverage Validation Loss: {avg_val_loss:.4f}\")\n","    print(f\"Average Validation Accuracy: {avg_val_accuracy:.4f}\")\n","\n","    return avg_val_loss, avg_val_accuracy\n","\n","# Define parameter values for Grid Search\n","dice_weight_vals = [0.2, 0.3, 0.4, 0.5]\n","focal_weight_vals = [0.1, 0.2, 0.3]\n","boundary_weight_vals = [0.1, 0.2, 0.3]\n","\n","best_loss = float('inf')  # Initialize the best loss\n","best_params = {}  # Store the best parameters\n","\n","# Iterate through all combinations of parameters for Grid Search\n","for dice_weight in dice_weight_vals:\n","    for focal_weight in focal_weight_vals:\n","        for boundary_weight in boundary_weight_vals:\n","            print(f\"\\nTesting dice_weight={dice_weight}, focal_weight={focal_weight}, boundary_weight={boundary_weight}\")\n","\n","            # Perform cross-validation with the current parameter combination\n","            avg_loss, avg_accuracy = cross_validate(dice_weight=dice_weight, focal_weight=focal_weight, boundary_weight=boundary_weight)\n","\n","            # Update the best parameters if a better loss is found\n","            if avg_loss < best_loss:\n","                best_loss = avg_loss\n","                best_params = {\n","                    'dice_weight': dice_weight,\n","                    'focal_weight': focal_weight,\n","                    'boundary_weight': boundary_weight\n","                }\n","\n","print(f\"\\nBest parameters: {best_params}\")\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T11:35:40.259982Z","iopub.execute_input":"2024-12-04T11:35:40.260297Z","iopub.status.idle":"2024-12-04T13:08:18.723663Z","shell.execute_reply.started":"2024-12-04T11:35:40.260263Z","shell.execute_reply":"2024-12-04T13:08:18.722936Z"},"id":"b_3aRr7H6RbV","outputId":"ab3ab5ee-99a8-4454-ed82-9aa2b964d3e2"},"outputs":[{"name":"stdout","text":"\nTesting dice_weight=0.2, focal_weight=0.1, boundary_weight=0.1\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.0846\nAverage Validation Accuracy: 0.1960\n\nTesting dice_weight=0.2, focal_weight=0.1, boundary_weight=0.2\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.2043\nAverage Validation Accuracy: 0.0022\n\nTesting dice_weight=0.2, focal_weight=0.1, boundary_weight=0.3\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.3184\nAverage Validation Accuracy: 0.1974\n\nTesting dice_weight=0.2, focal_weight=0.2, boundary_weight=0.1\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.2657\nAverage Validation Accuracy: 0.2158\n\nTesting dice_weight=0.2, focal_weight=0.2, boundary_weight=0.2\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.3136\nAverage Validation Accuracy: 0.0029\n\nTesting dice_weight=0.2, focal_weight=0.2, boundary_weight=0.3\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.3797\nAverage Validation Accuracy: 0.1307\n\nTesting dice_weight=0.2, focal_weight=0.3, boundary_weight=0.1\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.3693\nAverage Validation Accuracy: 0.1389\n\nTesting dice_weight=0.2, focal_weight=0.3, boundary_weight=0.2\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.4703\nAverage Validation Accuracy: 0.1416\n\nTesting dice_weight=0.2, focal_weight=0.3, boundary_weight=0.3\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.8368\nAverage Validation Accuracy: 0.4538\n\nTesting dice_weight=0.3, focal_weight=0.1, boundary_weight=0.1\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.5052\nAverage Validation Accuracy: 0.4652\n\nTesting dice_weight=0.3, focal_weight=0.1, boundary_weight=0.2\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.2340\nAverage Validation Accuracy: 0.2361\n\nTesting dice_weight=0.3, focal_weight=0.1, boundary_weight=0.3\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.0896\nAverage Validation Accuracy: 0.2102\n\nTesting dice_weight=0.3, focal_weight=0.2, boundary_weight=0.1\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.3407\nAverage Validation Accuracy: 0.1833\n\nTesting dice_weight=0.3, focal_weight=0.2, boundary_weight=0.2\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.4211\nAverage Validation Accuracy: 0.1852\n\nTesting dice_weight=0.3, focal_weight=0.2, boundary_weight=0.3\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.3976\nAverage Validation Accuracy: 0.1319\n\nTesting dice_weight=0.3, focal_weight=0.3, boundary_weight=0.1\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.3282\nAverage Validation Accuracy: 0.1392\n\nTesting dice_weight=0.3, focal_weight=0.3, boundary_weight=0.2\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.3613\nAverage Validation Accuracy: 0.0079\n\nTesting dice_weight=0.3, focal_weight=0.3, boundary_weight=0.3\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.4890\nAverage Validation Accuracy: 0.1966\n\nTesting dice_weight=0.4, focal_weight=0.1, boundary_weight=0.1\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: -0.0401\nAverage Validation Accuracy: 0.0182\n\nTesting dice_weight=0.4, focal_weight=0.1, boundary_weight=0.2\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.1717\nAverage Validation Accuracy: 0.1991\n\nTesting dice_weight=0.4, focal_weight=0.1, boundary_weight=0.3\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.4616\nAverage Validation Accuracy: 0.2449\n\nTesting dice_weight=0.4, focal_weight=0.2, boundary_weight=0.1\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.6678\nAverage Validation Accuracy: 0.4350\n\nTesting dice_weight=0.4, focal_weight=0.2, boundary_weight=0.2\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.1656\nAverage Validation Accuracy: 0.0069\n\nTesting dice_weight=0.4, focal_weight=0.2, boundary_weight=0.3\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.3616\nAverage Validation Accuracy: 0.1978\n\nTesting dice_weight=0.4, focal_weight=0.3, boundary_weight=0.1\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.3428\nAverage Validation Accuracy: 0.2063\n\nTesting dice_weight=0.4, focal_weight=0.3, boundary_weight=0.2\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.9576\nAverage Validation Accuracy: 0.4617\n\nTesting dice_weight=0.4, focal_weight=0.3, boundary_weight=0.3\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.6309\nAverage Validation Accuracy: 0.2267\n\nTesting dice_weight=0.5, focal_weight=0.1, boundary_weight=0.1\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.6530\nAverage Validation Accuracy: 0.4405\n\nTesting dice_weight=0.5, focal_weight=0.1, boundary_weight=0.2\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.2913\nAverage Validation Accuracy: 0.1848\n\nTesting dice_weight=0.5, focal_weight=0.1, boundary_weight=0.3\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.1608\nAverage Validation Accuracy: 0.1272\n\nTesting dice_weight=0.5, focal_weight=0.2, boundary_weight=0.1\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.1068\nAverage Validation Accuracy: 0.2124\n\nTesting dice_weight=0.5, focal_weight=0.2, boundary_weight=0.2\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.4238\nAverage Validation Accuracy: 0.2041\n\nTesting dice_weight=0.5, focal_weight=0.2, boundary_weight=0.3\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.3040\nAverage Validation Accuracy: 0.1510\n\nTesting dice_weight=0.5, focal_weight=0.3, boundary_weight=0.1\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.2212\nAverage Validation Accuracy: 0.1393\n\nTesting dice_weight=0.5, focal_weight=0.3, boundary_weight=0.2\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 0.3331\nAverage Validation Accuracy: 0.1315\n\nTesting dice_weight=0.5, focal_weight=0.3, boundary_weight=0.3\nDrop the training, to slow accuracy. Continue with next set of values\n\nAverage Validation Loss: 1.0846\nAverage Validation Accuracy: 0.4500\n\nBest parameters: {'dice_weight': 0.4, 'focal_weight': 0.1, 'boundary_weight': 0.1}\n","output_type":"stream"}],"execution_count":null}]}