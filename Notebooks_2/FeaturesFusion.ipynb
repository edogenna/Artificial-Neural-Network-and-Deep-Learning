{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10052167,"sourceType":"datasetVersion","datasetId":6193679},{"sourceId":10058605,"sourceType":"datasetVersion","datasetId":6198327},{"sourceId":10103266,"sourceType":"datasetVersion","datasetId":6231823},{"sourceId":191744,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":163443,"modelId":185804},{"sourceId":191952,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":163640,"modelId":185998}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"collapsed_sections":["FR7sUR3s7WUl","lADoABca7bdp","bBlmP0cx7eil","BPyTsNZK7Tjc","9m0uycvn7Tje","a0qlGnDF77JH","rCg_Zn0P7-ml","H7z6qcdY8BpS"],"toc_visible":true}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Setup model"],"metadata":{"id":"FR7sUR3s7WUl"}},{"cell_type":"code","source":["import os\n","import sys\n","from datetime import datetime\n","\n","import numpy as np\n","import pandas as pd\n","\n","import keras\n","\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import RandomTranslation\n","\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","seed = 9\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","\n","print(f\"TensorFlow version: {tf.__version__}\")\n","print(f\"Keras version: {tfk.__version__}\")\n","print(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")\n","BATCH_SIZE = 64\n","\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","tf.get_logger().setLevel('ERROR')\n","sys.stderr = open(os.devnull, 'w')"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"5Q3NRE477TjV"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Visualization"],"metadata":{"id":"lADoABca7bdp"}},{"cell_type":"code","source":["def create_segmentation_colormap(num_classes):\n","    \"\"\"\n","    Create a linear colormap using a predefined palette.\n","    Uses 'viridis' as default because it is perceptually uniform\n","    and works well for colorblindness.\n","    \"\"\"\n","    return plt.cm.viridis(np.linspace(0, 1, num_classes))\n","\n","def apply_colormap(label, colormap=None):\n","    \"\"\"\n","    Apply the colormap to a label.\n","    \"\"\"\n","    # Ensure label is 2D\n","    label = np.squeeze(label)\n","\n","    if colormap is None:\n","        num_classes = len(np.unique(label))\n","        colormap = create_segmentation_colormap(num_classes)\n","\n","    # Apply the colormap\n","    colored = colormap[label.astype(int)]\n","\n","    return colored\n","\n","class VizCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, dataset, frequency=5, num_classes=2):\n","        super().__init__()\n","        self.dataset = dataset\n","        self.frequency = frequency\n","        self.num_classes = num_classes\n","        self.dataset_iter = iter(dataset)  # Crea un iteratore per accedere ai dati\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if epoch % self.frequency == 0:  # Visualizza solo ogni \"frequency\" epochs\n","            try:\n","                # Estrai un batch di dati\n","                image, label = next(self.dataset_iter)\n","            except StopIteration:\n","                # Ricrea l'iteratore se i dati sono terminati\n","                self.dataset_iter = iter(self.dataset)\n","                image, label = next(self.dataset_iter)\n","\n","            # Prepara i dati per la predizione\n","            image = tf.expand_dims(image[0], 0)  # Estrai una sola immagine dal batch\n","            label = label[0]  # Etichetta corrispondente\n","            pred = self.model.predict(image, verbose=0)\n","            y_pred = tf.math.argmax(pred, axis=-1)\n","            y_pred = y_pred.numpy()\n","\n","            # Creazione della mappa colori\n","            colormap = create_segmentation_colormap(self.num_classes)\n","\n","            plt.figure(figsize=(16, 4))\n","\n","            # Immagine di input\n","            plt.subplot(1, 3, 1)\n","            plt.imshow(image[0])\n","            plt.title(\"Input Image\")\n","            plt.axis('off')\n","\n","            # Ground truth\n","            plt.subplot(1, 3, 2)\n","            colored_label = apply_colormap(label.numpy(), colormap)\n","            plt.imshow(colored_label)\n","            plt.title(\"Ground Truth Mask\")\n","            plt.axis('off')\n","\n","            # Predizione\n","            plt.subplot(1, 3, 3)\n","            colored_pred = apply_colormap(y_pred[0], colormap)\n","            plt.imshow(colored_pred)\n","            plt.title(\"Predicted Mask\")\n","            plt.axis('off')\n","\n","            plt.tight_layout()\n","            plt.show()\n","            plt.close()\n","\n"],"metadata":{"trusted":true,"id":"54Hu_LZj7TjY"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Load data and augmentation"],"metadata":{"id":"bBlmP0cx7eil"}},{"cell_type":"code","source":["training_data = np.load(\"/kaggle/input/datasetlomi/training_set_no_outliers.npz\")\n","test_data = np.load(\"/kaggle/input/datasetlomi/test_set.npz\")\n","images = training_data[\"images\"]/255\n","labels = training_data[\"labels\"]\n","print(images.shape)"],"metadata":{"trusted":true,"id":"V9ZQ055k7TjZ"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2)"],"metadata":{"trusted":true,"id":"ghZiUlNX7TjZ"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def add_channel(image, label):\n","    image = tf.cast(image, tf.float32)\n","    label = tf.cast(label, tf.float32)\n","    image = tf.expand_dims(image, axis=-1)\n","    label = tf.expand_dims(label, axis=-1)\n","    return image, label"],"metadata":{"trusted":true,"id":"neY3DDNI7Tja"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\"zoom\"\n","@tf.function\n","def zoom(image, label, zoom_range=(0.8, 1.2)):\n","    # Genera un fattore di zoom casuale\n","    zoom_factor = tf.random.uniform([], zoom_range[0], zoom_range[1])\n","\n","    # Ottieni le dimensioni originali\n","    original_height = tf.shape(image)[0]\n","    original_width = tf.shape(image)[1]\n","\n","    # Calcola le nuove dimensioni dopo lo zoom\n","    new_height = tf.cast(tf.cast(original_height, tf.float32) * zoom_factor, tf.int32)\n","    new_width = tf.cast(tf.cast(original_width, tf.float32) * zoom_factor, tf.int32)\n","\n","    # Ridimensiona l'immagine e la maschera\n","    zoomed_image = tf.image.resize(image, [new_height, new_width], method='bilinear')\n","    zoomed_label = tf.image.resize(label, [new_height, new_width], method='bilinear')  # Per maschere, meglio 'nearest'\n","\n","    # Ritaglia o pad per riportare alle dimensioni originali\n","    cropped_image = tf.image.resize_with_crop_or_pad(zoomed_image, original_height, original_width)\n","    cropped_label = tf.image.resize_with_crop_or_pad(zoomed_label, original_height, original_width)\n","\n","    return cropped_image, cropped_label\n","\n","@tf.function\n","def random_zoom(image, label, thr):\n","    prob = tf.random.uniform([])\n","\n","    image, label = tf.cond(\n","        prob < thr,\n","        lambda: (zoom(image, label)),\n","        lambda: (image, label)\n","    )\n","    return image, label\n","\n","def zoom_lambda(dataset, thr):\n","    return dataset.map(\n","        lambda x, y: random_zoom(x, y, thr),\n","        num_parallel_calls=tf.data.AUTOTUNE\n","    )\n"],"metadata":{"trusted":true,"id":"6gYrC1V27Tja"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\"contrast\"\n","@tf.function\n","def random_contrast(image, label, thr):\n","    prob = tf.random.uniform([], seed=seed)\n","    factor = tf.random.uniform([], minval=-4, maxval=4, seed=seed)\n","\n","\n","    image, label = tf.cond(\n","        prob < thr,\n","        lambda: (tf.image.adjust_contrast(image, factor), label),\n","        lambda: (image, label)\n","    )\n","    return image, label\n","\n","def contrast_lambda(dataset, thr):\n","    return dataset.map(\n","        lambda x, y: random_contrast(x, y, thr),\n","        num_parallel_calls=tf.data.AUTOTUNE\n","    )"],"metadata":{"trusted":true,"id":"InnB1_cX7Tja"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\"Flip Left Right\"\n","@tf.function\n","def random_flip_left_right(image, label, seed=None):\n","    if seed is None:\n","        seed = np.random.randint(0, 1000000)\n","\n","    flip_prob = tf.random.uniform([], seed=seed)\n","\n","    image, label = tf.cond(\n","        flip_prob > 0.5,\n","        lambda: (tf.image.flip_left_right(image), tf.image.flip_left_right(label)),\n","        lambda: (image, label)\n","    )\n","\n","    return image, label"],"metadata":{"trusted":true,"id":"3tViPZ8l7Tjb"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\"Flip Up Down\"\n","@tf.function\n","def random_flip_up_down(image, label, seed=None):\n","    if seed is None:\n","        seed = np.random.randint(0, 1000000)\n","\n","    flip_prob = tf.random.uniform([], seed=seed)\n","\n","    image, label = tf.cond(\n","        flip_prob > 0.5,\n","        lambda: (tf.image.flip_up_down(image), tf.image.flip_up_down(label)),\n","        lambda: (image, label)\n","    )\n","\n","    return image, label"],"metadata":{"trusted":true,"id":"9FtUx3Bl7Tjb"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\"Translation\"\n","@tf.function\n","def translation(image, label, max_translation=0.2, seed=None):\n","    height = tf.shape(image)[0]\n","    width = tf.shape(image)[1]\n","\n","    max_dx = tf.cast(max_translation * tf.cast(width, tf.float32), tf.int32)\n","    max_dy = tf.cast(max_translation * tf.cast(height, tf.float32), tf.int32)\n","\n","    dx = tf.random.uniform([], -max_dx, max_dx + 1, dtype=tf.int32, seed=seed)\n","    dy = tf.random.uniform([], -max_dy, max_dy + 1, dtype=tf.int32, seed=seed)\n","\n","    translated_image = tf.roll(image, shift=[dy, dx], axis=[0, 1])\n","    translated_label = tf.roll(label, shift=[dy, dx], axis=[0, 1])\n","\n","    return translated_image, translated_label\n","\n","\n","@tf.function\n","def random_translation(image, label, max_translation=0.2, seed=None):\n","    if seed is None:\n","        seed = np.random.randint(0, 1000000)\n","    flip_prob = tf.random.uniform([], seed=seed)\n","\n","    image, label = tf.cond(\n","        flip_prob > 0.7,\n","        lambda: (translation(image,label)),\n","        lambda: (image, label)\n","    )\n","    return image, label\n",""],"metadata":{"trusted":true,"id":"xuy7FSYO7Tjb"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\"Black Square\"\n","@tf.function\n","def random_black_square(image, label, max_square_ratio=0.2, seed=seed):\n","    # Calcola altezza e larghezza dell'immagine\n","    height = tf.shape(image)[0]\n","    width = tf.shape(image)[1]\n","\n","    # Determina la dimensione massima del quadrato, con un limite massimo di 32px\n","    max_square_size = tf.minimum(48, tf.cast(max_square_ratio * tf.minimum(tf.cast(height, tf.float32),\n","                                                                         tf.cast(width, tf.float32)), tf.int32))\n","\n","    # Assicura che il quadrato abbia senso nelle dimensioni dell'immagine\n","    max_square_size = tf.maximum(15, tf.minimum(max_square_size, tf.minimum(height, width)))\n","\n","    # Genera la dimensione del quadrato\n","    square_size = tf.random.uniform([], 1, max_square_size + 1, dtype=tf.int32, seed=seed)\n","\n","    # Genera la posizione del quadrato\n","    max_x = tf.maximum(0, width - square_size)\n","    max_y = tf.maximum(0, height - square_size)\n","\n","    start_x = tf.random.uniform([], 0, max_x + 1, dtype=tf.int32, seed=seed)\n","    start_y = tf.random.uniform([], 0, max_y + 1, dtype=tf.int32, seed=seed)\n","\n","    # Crea una maschera per \"cancellare\" il quadrato\n","    mask = tf.ones_like(image)\n","    mask = tf.tensor_scatter_nd_update(\n","        mask,\n","        indices=tf.stack(tf.meshgrid(\n","            tf.range(start_y, start_y + square_size),\n","            tf.range(start_x, start_x + square_size)\n","        ), axis=-1),\n","        updates=tf.zeros([square_size, square_size, tf.shape(image)[-1]], dtype=image.dtype)\n","    )\n","\n","    # Applica la maschera a immagine e label\n","    zeroed_image = image * mask\n","    zeroed_label = label * mask\n","\n","    return zeroed_image, zeroed_label\n","\n","@tf.function\n","def random_square(image, label, max_translation=0.2, seed=None):\n","    if seed is None:\n","        seed = np.random.randint(0, 1000000)\n","    prob = tf.random.uniform([], seed=seed)\n","\n","    image, label = tf.cond(\n","        prob > 0.7,\n","        lambda: random_black_square(image,label),\n","        lambda: (image, label)\n","    )\n","    return image, label\n",""],"metadata":{"trusted":true,"id":"WnR07ulw7Tjb"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["\"random_negative\"\n","@tf.function\n","def random_negative(image, label, seed=None):\n","    if seed is None:\n","        seed = np.random.randint(0, 1000000)\n","    flip_prob = tf.random.uniform([], seed=seed)\n","\n","    image, label = tf.cond(\n","        flip_prob > 0.7,\n","        lambda: (1-image, label),\n","        lambda: (image, label)\n","    )\n","\n","    return image, label"],"metadata":{"trusted":true,"id":"DitL3v537Tjc"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def duplicate_dataset(images, labels, quantity = 1):\n","    indices = np.where(np.any(labels == 4, axis=(1, 2)))[0]\n","\n","    images_to_duplicate = images[indices]\n","    labels_to_duplicate = labels[indices]\n","\n","    images_to_duplicate = np.concatenate([images_to_duplicate, images_to_duplicate], axis=0)\n","    labels_to_duplicate = np.concatenate([labels_to_duplicate, labels_to_duplicate], axis=0)\n","\n","    # Concatena ai dati originali\n","    images = np.concatenate([images, images_to_duplicate], axis=0)\n","    labels = np.concatenate([labels, labels_to_duplicate], axis=0)\n","\n","    images = np.concatenate([images, images[:quantity]], axis=0)\n","    labels = np.concatenate([labels, labels[:quantity]], axis=0)\n","\n","    return images, labels\n"],"metadata":{"trusted":true,"id":"q6V6ve5t7Tjc"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def to_datasett(X_train, y_train, augmentation = False, seed = seed, shuffle = True, batch_size = BATCH_SIZE, duplicate = False):\n","    if duplicate:\n","        X_train, y_train = duplicate_dataset(X_train, y_train, len(X_train))\n","        X_train, y_train = duplicate_dataset(X_train, y_train, len(X_train))\n","    dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","\n","    if shuffle:\n","        dataset = dataset.shuffle(buffer_size=batch_size * 2, seed=seed)\n","\n","    dataset = dataset.map(\n","                    lambda x, y: add_channel(x, y),\n","                    num_parallel_calls=tf.data.AUTOTUNE\n","                   )\n","\n","    if augmentation:\n","        dataset = dataset.map(\n","                        lambda x, y: random_flip_up_down(x,y,seed),\n","                        num_parallel_calls=tf.data.AUTOTUNE\n","                    )\n","        dataset = dataset.map(\n","                        lambda x, y: random_flip_left_right(x,y,seed),\n","                        num_parallel_calls=tf.data.AUTOTUNE\n","                    )\n","        dataset = dataset.map(\n","                        lambda x, y: random_translation(x,y,seed),\n","                        num_parallel_calls=tf.data.AUTOTUNE\n","                    )\n","        dataset = dataset.map(\n","                        lambda x, y: random_negative(x,y,seed),\n","                        num_parallel_calls=tf.data.AUTOTUNE\n","                    )\n","        dataset = dataset.map(\n","                        lambda x, y: random_square(x,y,seed),\n","                        num_parallel_calls=tf.data.AUTOTUNE\n","                    )\n","\n","        dataset = zoom_lambda(dataset,0.5)\n","\n","        dataset = contrast_lambda(dataset,0.6)\n","\n","\n","    # Batch the data\n","    dataset = dataset.batch(batch_size, drop_remainder=False)\n","    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","\n","    return dataset"],"metadata":{"trusted":true,"id":"XcfZc1rG7Tjc"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["train_dataset = to_datasett(X_train, y_train, augmentation = True, duplicate = True)\n","val_dataset = to_datasett(X_val, y_val, augmentation = False, duplicate = True)\n","\n","for image_batch, label_batch in train_dataset.take(1):  # Prendi un batch dal dataset\n","    print(\"Dimensioni del batch di immagini:\", image_batch.shape)\n","    print(\"Dimensioni del batch di label:\", label_batch.shape)"],"metadata":{"trusted":true,"id":"WekVOiGz7Tjc"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# **MODEL**"],"metadata":{"id":"BPyTsNZK7Tjc"}},{"cell_type":"markdown","source":["https://arxiv.org/pdf/2006.04868"],"metadata":{"id":"bbudFAAA7Tjd"}},{"cell_type":"code","source":["def encoder_block(input_tensor, filters, name=\"encoder_block\"):\n","    \"\"\"Blocchi encoder con convoluzioni, BatchNormalization, ReLU e riduzione delle dimensioni spaziali.\"\"\"\n","    # Prima Convoluzione\n","    x = layers.Conv2D(filters, (3, 3), padding=\"same\", name=f\"{name}_conv1\")(input_tensor)\n","    x = layers.BatchNormalization(name=f\"{name}_bn1\")(x)\n","    x = layers.ReLU(name=f\"{name}_relu1\")(x)\n","\n","    # Seconda Convoluzione\n","    x = layers.Conv2D(filters, (3, 3), padding=\"same\", name=f\"{name}_conv2\")(x)\n","    x = layers.BatchNormalization(name=f\"{name}_bn2\")(x)\n","    x = layers.ReLU(name=f\"{name}_relu2\")(x)\n","\n","    # Riduzione della dimensione spaziale\n","    pooled = layers.MaxPooling2D((2, 2), strides=2, name=f\"{name}_pool\")(x)\n","\n","    return pooled, pooled  # pooled: feature map dimezzata, x: feature map per le skip connections\n"],"metadata":{"trusted":true,"id":"L33UrmV47Tjd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","def aspp_block(input_tensor, filters, name=\"ASPP\"):\n","\n","    # Convoluzione 1x1\n","    conv1 = layers.Conv2D(filters, (1, 1), padding=\"same\", activation=\"relu\", name=f\"{name}_conv1\")(input_tensor)\n","\n","    # Convoluzioni dilatate (3x3) con diversi tassi di dilatazione\n","    conv3_1 = layers.Conv2D(filters, (3, 3), dilation_rate=1, padding=\"same\", activation=\"relu\", name=f\"{name}_conv3_6\")(input_tensor)\n","    conv3_2 = layers.Conv2D(filters, (3, 3), dilation_rate=4, padding=\"same\", activation=\"relu\", name=f\"{name}_conv3_12\")(input_tensor)\n","    conv3_3 = layers.Conv2D(filters, (3, 3), dilation_rate=8, padding=\"same\", activation=\"relu\", name=f\"{name}_conv3_18\")(input_tensor)\n","\n","    # Global Average Pooling\n","    global_avg = layers.GlobalAveragePooling2D(name=f\"{name}_gap\")(input_tensor)\n","    global_avg = layers.Reshape((1, 1, input_tensor.shape[-1]), name=f\"{name}_reshape\")(global_avg)\n","    global_avg = layers.Conv2D(filters, (1, 1), padding=\"same\", activation=\"relu\", name=f\"{name}_conv_global\")(global_avg)\n","    global_avg = layers.UpSampling2D(size=(input_tensor.shape[1], input_tensor.shape[2]), interpolation=\"bilinear\", name=f\"{name}_upsample\")(global_avg)\n","\n","    # Concatenazione\n","    x = layers.Concatenate(name=f\"{name}_concat\")([conv1, conv3_1, conv3_2, conv3_3, global_avg])\n","\n","    # Convoluzione Finale per Ridurre i Canali\n","    x = layers.Conv2D(filters, (1, 1), padding=\"same\", activation=\"relu\", name=f\"{name}_conv_out\")(x)\n","\n","    return x\n"],"metadata":{"trusted":true,"id":"B2jV2FG87Tjd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from tensorflow.keras.layers import Add, Concatenate, Dense, GlobalAveragePooling2D, Multiply, Lambda\n","\n","def gated_skip_connection(x, skip, mode=\"add\", gating=\"learnable\", name=\"gated_connection\"):\n","    if gating == \"learnable\":\n","        # Learnable scalars for gating\n","        alpha = tf.Variable(0.5, trainable=True, name=f\"{name}_alpha\")\n","        beta = tf.Variable(0.5, trainable=True, name=f\"{name}_beta\")\n","\n","        # Normalize weights with a softmax\n","        alpha, beta = tf.nn.softmax([alpha, beta], axis=0)\n","        if mode == \"add\":\n","            output = Add(name=f\"{name}_add\")([alpha * x, beta * skip])\n","        elif mode == \"concat\":\n","            output = Concatenate(name=f\"{name}_concat\")([alpha * x, beta * skip])\n","        else:\n","            raise ValueError(\"Unsupported mode. Use 'add' or 'concat'.\")\n","\n","    elif gating == \"dynamic\":\n","        # Dynamic gating based on skip and decoder features\n","        combined = Concatenate(name=f\"{name}_dynamic_concat\")([x, skip])\n","        gate = GlobalAveragePooling2D(name=f\"{name}_gap\")(combined)\n","        gate = Dense(1, activation=\"sigmoid\", name=f\"{name}_gate\")(gate)\n","\n","        # Apply gating\n","        gate = Lambda(lambda z: tf.expand_dims(tf.expand_dims(z, axis=1), axis=1), name=f\"{name}_expand\")(gate)\n","        gated_skip = Multiply(name=f\"{name}_multiply\")([skip, gate])\n","        output = Add(name=f\"{name}_add_dynamic\")([x, gated_skip])\n","\n","    else:\n","        raise ValueError(\"Unsupported gating mode. Use 'learnable' or 'dynamic'.\")\n","\n","    return output\n"],"metadata":{"trusted":true,"id":"zbZ-7Zww7Tjd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from tensorflow.keras import layers, Model\n","\n","def network1(input_shape=(64, 128, 1), num_classes=5, filter_factor=0.5):\n","    inputs = layers.Input(shape=input_shape)\n","\n","    # Blocco 1\n","    x = layers.Conv2D(int(64 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"block1_conv1\")(inputs)\n","    x = layers.Conv2D(int(64 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"block1_conv2\")(x)\n","    block1 = x\n","    x = layers.MaxPooling2D((2, 2), strides=2, name=\"block1_pool\")(x)\n","\n","    # Blocco 2\n","    x = layers.Conv2D(int(128 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"block2_conv1\")(x)\n","    x = layers.Conv2D(int(128 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"block2_conv2\")(x)\n","    block2 = x\n","    x = layers.MaxPooling2D((2, 2), strides=2, name=\"block2_pool\")(x)\n","\n","    # Blocco 3\n","    x = layers.Conv2D(int(256 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"block3_conv1\")(x)\n","    x = layers.Dropout(0.3, name=\"block3_dropout1\")(x)\n","    x = layers.Conv2D(int(256 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"block3_conv2\")(x)\n","    x = layers.Dropout(0.3, name=\"block3_dropout2\")(x)\n","    x = layers.Conv2D(int(256 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"block3_conv3\")(x)\n","    block3 = x\n","    x = layers.MaxPooling2D((2, 2), strides=2, name=\"block3_pool\")(x)\n","\n","    # Blocco 4\n","    x = layers.Conv2D(int(512 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"block4_conv1\")(x)\n","    x = layers.Dropout(0.3, name=\"block4_dropout1\")(x)\n","    x = layers.Conv2D(int(512 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"block4_conv2\")(x)\n","    x = layers.Dropout(0.3, name=\"block4_dropout2\")(x)\n","    x = layers.Conv2D(int(512 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"block4_conv3\")(x)\n","    block4 = x\n","    x = layers.MaxPooling2D((2, 2), strides=2, name=\"block4_pool\")(x)\n","\n","    # Blocco 5\n","    x = layers.Conv2D(int(512 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"block5_conv1\")(x)\n","    x = layers.Dropout(0.3, name=\"block5_dropout1\")(x)\n","    x = layers.Conv2D(int(512 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"block5_conv2\")(x)\n","    x = layers.Dropout(0.3, name=\"block5_dropout2\")(x)\n","    x = layers.Conv2D(int(512 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"block5_conv3\")(x)\n","    block5 = x\n","    x = layers.MaxPooling2D((2, 2), strides=2, name=\"block5_pool\")(x)\n","\n","    # Bottleneck - Secondo Metodo\n","    dilation_1 = layers.Conv2D(int(256 * filter_factor), (3, 3), dilation_rate=1, padding=\"same\", activation=\"relu\", name=\"bottleneck_dilation1\")(x)\n","    dilation_2 = layers.Conv2D(int(256 * filter_factor), (3, 3), dilation_rate=2, padding=\"same\", activation=\"relu\", name=\"bottleneck_dilation2\")(x)\n","    dilation_3 = layers.Conv2D(int(256 * filter_factor), (3, 3), dilation_rate=4, padding=\"same\", activation=\"relu\", name=\"bottleneck_dilation3\")(x)\n","    global_pool = layers.GlobalAveragePooling2D(name=\"bottleneck_global_pool\")(x)\n","    global_pool = layers.Reshape((1, 1, int(512 * filter_factor)), name=\"bottleneck_global_reshape\")(global_pool)\n","    global_pool = layers.Conv2D(int(256 * filter_factor), (1, 1), activation=\"relu\", name=\"bottleneck_global_conv\")(global_pool)\n","    global_pool = layers.UpSampling2D(size=(x.shape[1], x.shape[2]), interpolation=\"bilinear\", name=\"bottleneck_global_upsample\")(global_pool)\n","\n","    # Concatenazione Bottleneck\n","    x = layers.Concatenate(name=\"bottleneck_concat\")([dilation_1, dilation_2, dilation_3, global_pool])\n","    x = layers.Conv2D(int(512 * filter_factor), (1, 1), padding=\"same\", activation=\"relu\", name=\"bottleneck_output\")(x)\n","\n","    # Decoder (Upsampling)\n","    x = layers.UpSampling2D((2, 2), name=\"decoder_network1_upsample0\")(x)\n","    x = layers.Conv2D(int(512 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"decoder_network1_conv1\")(x)\n","\n","    # Gated Skip Connection for Block 5\n","    x = gated_skip_connection(x, block5, mode=\"add\", gating=\"learnable\", name=\"decoder_network1_gated1\")\n","    x = layers.Conv2D(int(512 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"decoder_network1_conv2\")(x)\n","    x = layers.BatchNormalization(name=\"decoder_network1_bn1\")(x)\n","\n","    # Gated Skip Connection for Block 4\n","    x = layers.UpSampling2D((2, 2), name=\"decoder_network1_upsample1\")(x)\n","    x = gated_skip_connection(x, block4, mode=\"add\", gating=\"learnable\", name=\"decoder_network1_gated2\")\n","    x = layers.Conv2D(int(256 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"decoder_network1_conv3\")(x)\n","    x = layers.BatchNormalization(name=\"decoder_network1_bn2\")(x)\n","\n","    # Gated Skip Connection for Block 3\n","    x = layers.UpSampling2D((2, 2), name=\"decoder_network1_upsample2\")(x)\n","    x = gated_skip_connection(x, block3, mode=\"add\", gating=\"learnable\", name=\"decoder_network1_gated3\")\n","    x = layers.Conv2D(int(128 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"decoder_network1_conv4\")(x)\n","    x = layers.BatchNormalization(name=\"decoder_network1_bn3\")(x)\n","\n","    # Gated Skip Connection for Block 2\n","    x = layers.UpSampling2D((2, 2), name=\"decoder_network1_upsample3\")(x)\n","    x = gated_skip_connection(x, block2, mode=\"add\", gating=\"learnable\", name=\"decoder_network1_gated4\")\n","    x = layers.Conv2D(int(64 * filter_factor), (3, 3), padding=\"same\", activation=\"relu\", name=\"decoder_network1_conv5\")(x)\n","    x = layers.BatchNormalization(name=\"decoder_network1_bn4\")(x)\n","\n","    # Final Upsampling\n","    x = layers.UpSampling2D((2, 2), name=\"decoder_network1_upsample4\")(x)\n","    outputs = layers.Conv2D(num_classes, (1, 1), activation=\"softmax\", name=\"output1\")(x)\n","\n","    model = tfk.Model(inputs=inputs, outputs=outputs)\n","    return model\n"],"metadata":{"trusted":true,"id":"kIVznOas7Tjd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["model = network1()\n","\n","# Print a detailed summary of the model with expanded nested layers and trainable parameters.\n","#model.summary(expand_nested=True, show_trainable=True)\n","\n","# Generate and display a graphical representation of the model architecture.\n","#tf.keras.utils.plot_model(model, show_trainable=True, expand_nested=True, dpi=70)\n","\n","#tf.keras.utils.plot_model(model, show_trainable=True, expand_nested=True, dpi=70)"],"metadata":{"trusted":true,"id":"ubmp7lC87Tje"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Mean Intersection over union"],"metadata":{"id":"9m0uycvn7Tje"}},{"cell_type":"code","source":["class MeanIntersectionOverUnion(tf.keras.metrics.MeanIoU):\n","    def __init__(self, num_classes, labels_to_exclude=[0], name=\"mean_iou\", dtype=None, **kwargs):\n","        \"\"\"\n","        Aggiunto **kwargs per gestire parametri inattesi come `ignore_class`.\n","        \"\"\"\n","        super(MeanIntersectionOverUnion, self).__init__(num_classes=num_classes, name=name, dtype=dtype)\n","        if labels_to_exclude is None:\n","            labels_to_exclude = [0]\n","        self.labels_to_exclude = labels_to_exclude\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        y_pred = tf.math.argmax(y_pred, axis=-1)\n","        y_true = tf.reshape(y_true, [-1])\n","        y_pred = tf.reshape(y_pred, [-1])\n","\n","        for label in self.labels_to_exclude:\n","            mask = tf.not_equal(y_true, label)\n","            y_true = tf.boolean_mask(y_true, mask)\n","            y_pred = tf.boolean_mask(y_pred, mask)\n","\n","        return super().update_state(y_true, y_pred, sample_weight)\n","\n","# Registra la classe personalizzata\n","tf.keras.utils.get_custom_objects()[\"MeanIntersectionOverUnion\"] = MeanIntersectionOverUnion\n"],"metadata":{"trusted":true,"id":"TmMbrtlg7Tje"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Losses"],"metadata":{"id":"a0qlGnDF77JH"}},{"cell_type":"code","source":["labels_flat = y_train.reshape(-1)  # Appiattisci l'array per considerare tutti i pixel\n","\n","# Conta la frequenza di ogni classe\n","num_classes = 5  # Modifica in base al numero di classi nel tuo dataset\n","labels_flat = labels_flat.astype(int)  # Converte i dati in interi\n","\n","# Conta la frequenza di ogni classe\n","class_frequencies = np.bincount(labels_flat, minlength=num_classes)\n","\n","# Stampa le frequenze\n","print(f\"Frequenze delle classi: {class_frequencies}\")\n","\n","total_samples = np.sum(class_frequencies)\n","\n","# Calcola i pesi di classe\n","class_weights = total_samples / (len(class_frequencies) * class_frequencies)\n","\n","\n","# Conversione in dizionario per TensorFlow\n","class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n","print(f\"Dizionario dei pesi di classe: {class_weights_dict}\")\n","\n","# Funzione di perdita con pesi di classe\n","loss = tf.keras.losses.SparseCategoricalCrossentropy()\n","\n","\n","\n","def weighted_loss(y_true, y_pred):\n","    y_true = tf.cast(y_true, tf.int32)  # Assicurati che i valori siano interi\n","    weights = tf.gather(class_weights, y_true)  # Recupera i pesi in base alle etichette\n","    weights = tf.cast(weights, tf.float32)  # Converte i pesi in float32\n","    unweighted_loss = loss(y_true, y_pred)\n","    weighted_loss = unweighted_loss * weights\n","    return tf.reduce_mean(weighted_loss)"],"metadata":{"trusted":true,"id":"O44C2iTv7Tje"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["class ComboLoss:\n","    def __init__(self, alpha=0.5, dice_smooth=1e-7, class_weights=None):\n","        self.alpha = alpha\n","        self.dice_smooth = dice_smooth\n","        self.class_weights = class_weights\n","\n","    def dice_loss(self, y_true, y_pred):\n","        y_true = tf.cast(tf.one_hot(tf.cast(y_true[..., 0], tf.int32), depth=y_pred.shape[-1]), tf.float32)\n","        intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n","        cardinality = tf.reduce_sum(y_true, axis=[1, 2]) + tf.reduce_sum(y_pred, axis=[1, 2])\n","        dice = (2. * intersection + self.dice_smooth) / (cardinality + self.dice_smooth)\n","        return 1 - tf.reduce_mean(dice)\n","\n","    def weighted_loss(self, y_true, y_pred):\n","        y_true = tf.cast(y_true, tf.int32)  # Assicurati che i valori siano interi\n","        weights = tf.gather(class_weights, y_true)  # Recupera i pesi in base alle etichette\n","        weights = tf.cast(weights, tf.float32)  # Converte i pesi in float32\n","        unweighted_loss = loss(y_true, y_pred)\n","        weighted_loss = unweighted_loss * weights\n","        return tf.reduce_mean(weighted_loss)\n","\n","    def __call__(self, y_true, y_pred):\n","        wce = self.weighted_loss(y_true, y_pred)\n","        dice = self.dice_loss(y_true, y_pred)\n","        return self.alpha * wce + (1 - self.alpha) * dice\n","\n","    def get_config(self):\n","        return {\n","            \"alpha\": self.alpha,\n","            \"dice_smooth\": self.dice_smooth,\n","            \"class_weights\": self.class_weights\n","        }\n","\n","    @classmethod\n","    def from_config(cls, config):\n","        return cls(**config)\n","\n","\n","combo_loss = ComboLoss(alpha=0.5, class_weights=class_weights)"],"metadata":{"trusted":true,"id":"m7hJN6Cx7Tje"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from tensorflow.keras import backend as K\n","\n","def iou_loss(y_true, y_pred, smooth=1e-7):\n","    \"\"\"\n","    Loss basata su Intersection over Union (IoU).\n","\n","    Args:\n","        y_true (Tensor): Ground truth, dimensione (batch, height, width, num_classes).\n","        y_pred (Tensor): Predizioni del modello, stessa dimensione di y_true.\n","        smooth (float): Fattore di stabilizzazione per evitare divisioni per zero.\n","\n","    Returns:\n","        Tensor: Valore medio della IoU Loss.\n","    \"\"\"\n","    if y_true.shape[-1] != y_pred.shape[-1]:\n","        y_true = tf.one_hot(tf.cast(y_true[..., 0], tf.int32), depth=tf.shape(y_pred)[-1])\n","\n","    # Calcolo di Intersection e Union\n","    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2])\n","    union = tf.reduce_sum(y_true + y_pred, axis=[1, 2]) - intersection\n","    iou = (intersection + smooth) / (union + smooth)\n","\n","    # Loss come complemento dell'IoU\n","    return 1 - tf.reduce_mean(iou)\n"],"metadata":{"trusted":true,"id":"8KoSXqQX7Tje"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Compilation and training"],"metadata":{"id":"rCg_Zn0P7-ml"}},{"cell_type":"code","source":["model.compile(\n","    optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001),\n","    loss=combo_loss,\n","    metrics=[\n","        \"accuracy\",\n","        MeanIntersectionOverUnion(num_classes=5, labels_to_exclude=[0])\n","    ]\n",")"],"metadata":{"trusted":true,"id":"Rf-JSN097Tje"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["patience = 50\n","epochs = 1000\n","\n","early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_accuracy',\n","    mode='max',\n","    patience=patience,\n","    restore_best_weights=True\n",")\n","\n","viz_callback = VizCallback(val_dataset, frequency=5, num_classes=5)"],"metadata":{"trusted":true,"id":"0FbOQekV7Tjf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["history = model.fit(\n","    train_dataset,   # Dataset con immagini e label\n","    validation_data=val_dataset,\n","    epochs=epochs,\n","    verbose=1,\n","    callbacks=[early_stopping, viz_callback]\n",")\n","\n","# Calculate and print the final validation accuracy\n","#final_val_meanIoU = round(max(history['val_mean_iou'])* 100, 2)\n","#print(f'Final validation Mean Intersection Over Union: {final_val_meanIoU}%')\n","\n","# Definisci il percorso di salvataggio nella directory di lavoro\n","model.save(\"/kaggle/working/FirstPart.keras\")\n","\n","# Delete the model to free up resources\n","#del model"],"metadata":{"trusted":true,"id":"F7z9pzPa7Tjf"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Testing"],"metadata":{"id":"H7z6qcdY8BpS"}},{"cell_type":"code","source":["model_filename = \"FirstPart.keras\"\n","\n","X_test = np.load(\"/kaggle/input/datasetlomi/test_set.npz\")\n","model = tf.keras.models.load_model(\n","    \"/kaggle/working/FirstPart.keras\",\n","    custom_objects={'ComboLoss': ComboLoss}\n",")\n","\n","preds = model.predict(X_test[\"images\"]/255)\n","preds = np.argmax(preds, axis=-1)\n","print(f\"Predictions shape: {preds.shape}\")"],"metadata":{"trusted":true,"id":"Vv4FPKll7Tjf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def y_to_df(y) -> pd.DataFrame:\n","    \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n","    n_samples = len(y)\n","    y_flat = y.reshape(n_samples, -1)\n","    df = pd.DataFrame(y_flat)\n","    df[\"id\"] = np.arange(n_samples)\n","    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n","    return df[cols]"],"metadata":{"trusted":true,"id":"9CeaOOX07Tjf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Create and download the csv submission file\n","timestep_str = model_filename.replace(\"model_\", \"\").replace(\".keras\", \"\")\n","submission_filename = f\"submission_{timestep_str}.csv\"\n","submission_df = y_to_df(preds)\n","submission_df.to_csv(submission_filename, index=False)"],"metadata":{"trusted":true,"id":"OtlFKJ7s7Tjf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, Multiply\n","\n","def squeeze_excite_block(inputs, ratio=8):\n","    init = inputs\n","    channel_axis = -1  # Canali sull'ultima dimensione\n","    filters = init.shape[channel_axis]\n","    se_shape = (1, 1, filters)\n","\n","    # Squeeze: Global Average Pooling\n","    se = GlobalAveragePooling2D()(init)\n","    se = Reshape(se_shape)(se)\n","\n","    # Excitation: Bottleneck + Sigmoid scaling\n","    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n","    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n","\n","    # Scaling i canali dell'input\n","    x = Multiply()([init, se])\n","    return x\n"],"metadata":{"trusted":true,"id":"nX-4kVOw7Tjf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from tensorflow.keras.regularizers import l2\n","\n","def network2(input_shape=(64, 128, 1), num_classes=5, dropout_rate=0.3):\n","    # Carica il modello pre-addestrato\n","    pretrained_model = tf.keras.models.load_model(\n","        \"/kaggle/working/FirstPart.keras\",\n","        custom_objects={'weighted_loss': weighted_loss}\n","    )\n","\n","    # Blocca l'addestramento del modello pre-addestrato\n","    for layer in pretrained_model.layers:\n","        layer.trainable = False\n","\n","    # Recupera gli skip connection e l'output\n","    block1 = pretrained_model.get_layer(\"block1_conv2\").output\n","    block2 = pretrained_model.get_layer(\"block2_conv2\").output\n","    block3 = pretrained_model.get_layer(\"block3_conv3\").output\n","    block4 = pretrained_model.get_layer(\"block4_conv3\").output\n","    block5 = pretrained_model.get_layer(\"block5_conv3\").output\n","    outputs1 = pretrained_model.get_layer(\"output1\").output\n","\n","    print(\"Input del modello salvato:\", pretrained_model.input_shape)\n","    print(\"Output del modello salvato:\", outputs1.shape)\n","\n","    # FUSIONE\n","    x = layers.Conv2D(1, (1, 1), activation=\"softmax\", name=\"output1_compressed\")(outputs1)\n","    multiplication = layers.Multiply(name=\"multiplication\")([x, pretrained_model.input])\n","    print(\"Dopo moltiplicazione: \", multiplication.shape)\n","\n","    # SECONDO ENCODER\n","    x, skip1 = encoder_block(multiplication, 64, name=\"encoder_block1_network2\")\n","    x = squeeze_excite_block(x)\n","    x = layers.Dropout(dropout_rate, name=\"dropout_encoder1\")(x)  # Dropout aggiunto\n","    print(\"x1: \", x.shape)\n","\n","    x, skip2 = encoder_block(x, 128, name=\"encoder_block2_network2\")\n","    x = squeeze_excite_block(x)\n","    x = layers.Dropout(dropout_rate, name=\"dropout_encoder2\")(x)\n","    print(\"x2: \", x.shape)\n","\n","    x, skip3 = encoder_block(x, 256, name=\"encoder_block3_network2\")\n","    x = squeeze_excite_block(x)\n","    x = layers.SpatialDropout2D(dropout_rate, name=\"spatial_dropout_encoder3\")(x)\n","    print(\"x3: \", x.shape)\n","\n","    output_encoder2, skip4 = encoder_block(x, 512, name=\"encoder_block4_network2\")\n","    x = squeeze_excite_block(x)\n","    x = layers.SpatialDropout2D(dropout_rate, name=\"spatial_dropout_encoder4\")(output_encoder2)\n","    print(\"x4: \", x.shape)\n","\n","    passo_attraverso_ASPP = aspp_block(x, 64, \"PIPPO2\")\n","\n","    # SECONDO DECODER\n","    x = layers.Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", kernel_regularizer=l2(1e-4))(passo_attraverso_ASPP)\n","    x = layers.Concatenate()([passo_attraverso_ASPP, block5, output_encoder2])\n","    x = layers.Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\n","    x = layers.Dropout(dropout_rate, name=\"dropout_decoder1\")(x)\n","    print(\"Input secondo decoder x1: \", x.shape)\n","\n","    # Block 4 -> Block 3\n","    x = layers.UpSampling2D((2, 2))(x)\n","    x = layers.Concatenate()([x, block4, skip3])\n","    x = layers.Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\n","    x = layers.Dropout(dropout_rate, name=\"dropout_decoder2\")(x)\n","    print(\"Input secondo decoder x2: \", x.shape)\n","\n","    # Block 3 -> Block 2\n","    x = layers.UpSampling2D((2, 2))(x)\n","    x = layers.Concatenate()([x, block3, skip2])\n","    x = layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Dropout(dropout_rate, name=\"dropout_decoder3\")(x)\n","    print(\"Input secondo decoder x3: \", x.shape)\n","\n","    # Block 2 -> Block 1\n","    x = layers.UpSampling2D((2, 2))(x)\n","    x = layers.Concatenate()([x, block2, skip1])\n","    x = layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\n","    x = layers.Dropout(dropout_rate, name=\"dropout_decoder4\")(x)\n","    print(\"Input secondo decoder x4: \", x.shape)\n","\n","    # Output finale\n","    x = layers.UpSampling2D((2, 2))(x)\n","    x = layers.Conv2D(num_classes, (1, 1), activation=\"softmax\", name=\"output2\")(x)\n","\n","    # Output combinato\n","    final_output = layers.Concatenate()([outputs1, x])\n","    final_output = layers.Conv2D(5, (1, 1), activation=\"softmax\", name=\"final_output\")(final_output)\n","\n","    model = tfk.Model(inputs=pretrained_model.input, outputs=final_output)\n","    print(\"Final output: \", final_output.shape)\n","\n","    return model\n"],"metadata":{"trusted":true,"id":"FiXqDrnX7Tjf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["model = network2()\n","#model.summary(expand_nested=True, show_trainable=True)\n","#tf.keras.utils.plot_model(model, show_trainable=True, expand_nested=True, dpi=70)"],"metadata":{"trusted":true,"id":"E043osls7Tjf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["model.compile(\n","        loss=iou_loss,\n","        optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001),\n","        metrics=[\n","            \"accuracy\",\n","            MeanIntersectionOverUnion(num_classes=5, labels_to_exclude=[0])\n","        ]\n",")"],"metadata":{"trusted":true,"id":"5sLlvHze7Tjf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_mean_iou',\n","    mode='max',\n","    patience=50,\n","    restore_best_weights=True\n",")\n","\n","viz_callback = VizCallback(val_dataset, frequency=5, num_classes=5)"],"metadata":{"trusted":true,"id":"Ti9mqEkw7Tjg"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["history = model.fit(\n","    train_dataset,\n","    epochs=epochs,\n","    validation_data=val_dataset,\n","    callbacks=[early_stopping, viz_callback],\n","    verbose=1\n",").history\n","\n","# Calculate and print the final validation accuracy\n","#final_val_meanIoU = round(max(history['val_mean_iou'])* 100, 2)\n","#print(f'Final validation Mean Intersection Over Union: {final_val_meanIoU}%')\n","\n","# Definisci il percorso di salvataggio nella directory di lavoro\n","model.save(\"/kaggle/working/SecondPart.keras\")\n","\n","# Delete the model to free up resources\n","del model"],"metadata":{"trusted":true,"id":"Vg6pburX7Tjg"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["model_filename = \"SecondPart.keras\"\n","\n","X_test = np.load(\"/kaggle/input/datasetlomi/test_set.npz\")\n","model = tf.keras.models.load_model(\n","    \"/kaggle/working/SecondPart.keras\",\n","    custom_objects={'iou_loss': iou_loss}\n",")\n","\n","preds = model.predict(X_test[\"images\"]/255)\n","preds = np.argmax(preds, axis=-1)\n","print(f\"Predictions shape: {preds.shape}\")"],"metadata":{"trusted":true,"id":"Ql_LGS1X7Tjk"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["def y_to_df(y) -> pd.DataFrame:\n","    \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n","    n_samples = len(y)\n","    y_flat = y.reshape(n_samples, -1)\n","    df = pd.DataFrame(y_flat)\n","    df[\"id\"] = np.arange(n_samples)\n","    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n","    return df[cols]"],"metadata":{"trusted":true,"id":"giofcbq_7Tjk"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Create and download the csv submission file\n","timestep_str = model_filename.replace(\"model_\", \"\").replace(\".keras\", \"\")\n","submission_filename = f\"submission_{timestep_str}.csv\"\n","submission_df = y_to_df(preds)\n","submission_df.to_csv(submission_filename, index=False)"],"metadata":{"trusted":true,"id":"alZdu4cs7Tjk"},"outputs":[],"execution_count":null}]}